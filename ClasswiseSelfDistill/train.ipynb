{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularizing Class-wise Predictions via Self-knowledge Distillation, 20 `CVPR\n",
    "\n",
    "#### code modified from https://github.com/alinlab/cs-kd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import os, logging\n",
    "import easydict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable, grad\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import models\n",
    "#from utils import progress_bar, set_logging_defaults\n",
    "from datasets import load_dataset\n",
    "\n",
    "args = easydict.EasyDict({\"lr\": 0.1,\n",
    "                         \"resume\": False,\n",
    "                         \"model\": \"CIFAR_ResNet18\",\n",
    "                         \"name\": '0',\n",
    "                         \"batch_size\": 128,\n",
    "                         \"epoch\": 200,\n",
    "                         \"decay\": 1e-4,\n",
    "                         \"ngpu\": 1,\n",
    "                         \"sgpu\": 0,\n",
    "                         \"dataset\": 'cifar100',\n",
    "                         \"dataroot\": './data/',\n",
    "                         \"saveroot\": './results',\n",
    "                         \"cls\": True,\n",
    "                         \"temp\": 4.0,\n",
    "                         \"lamda\": 1.0})\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "best_val = 0  # best validation accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset: CIFAR100\n",
    "### Model: ResNet-18\n",
    "\n",
    "#### trainloader 에서 pair sampling\n",
    "input : [batch_size, batch_size] -> 2*B 개의 이미지\n",
    "\n",
    "앞의 batch와 뒤의 batch의 label은 서로 일치함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset: cifar100\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "print('==> Preparing dataset: {}'.format(args.dataset))\n",
    "trainloader, valloader = load_dataset(args.dataset, args.dataroot, 'pair', batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train dataset:  50000\n",
      "Number of validation dataset:  10000\n",
      "==> Building model: CIFAR_ResNet18\n",
      "4\n",
      "Using CUDA..\n"
     ]
    }
   ],
   "source": [
    "num_class = trainloader.dataset.num_classes\n",
    "print('Number of train dataset: ' ,len(trainloader.dataset))\n",
    "print('Number of validation dataset: ' ,len(valloader.dataset))\n",
    "\n",
    "net = models.load_model(args.model, num_class)\n",
    "\n",
    "if use_cuda:\n",
    "    torch.cuda.set_device(args.sgpu)\n",
    "    net = net.cuda()\n",
    "\n",
    "if args.ngpu > 1:\n",
    "    net = torch.nn.DataParallel(net, device_ids=list(range(args.sgpu, args.sgpu + args.ngpu)))\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=0.9, weight_decay=args.decay)\n",
    "\n",
    "logdir = os.path.join(args.saveroot, args.dataset, args.model, args.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train input example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 32, 32]) torch.Size([256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8ce03c4520>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "inputs, targets = next(iter(trainloader))\n",
    "#inputs, targets = inputs.cuda(), targets.cuda()\n",
    "print(inputs.size(), targets.size())\n",
    "\n",
    "split_idx = inputs.size(0) // 2\n",
    "grid = torchvision.utils.make_grid(torch.stack((inputs[0], inputs[split_idx]), 0), normalize=True)\n",
    "plt.imshow(np.transpose(grid.numpy(), (1,2,0)), interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KDLoss(nn.Module):\n",
    "    def __init__(self, temp_factor):\n",
    "        super(KDLoss, self).__init__()\n",
    "        self.temp_factor = temp_factor\n",
    "        self.kl_div = nn.KLDivLoss(reduction=\"sum\")\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        log_p = torch.log_softmax(input/self.temp_factor, dim=1)\n",
    "        q = torch.softmax(target/self.temp_factor, dim=1)\n",
    "        loss = self.kl_div(log_p, q)*(self.temp_factor**2)/input.size(0)\n",
    "        return loss\n",
    "\n",
    "kdloss = KDLoss(args.temp)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    global best_val\n",
    "    net.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "\n",
    "    # Define a data loader for evaluating\n",
    "    loader = valloader\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = torch.mean(criterion(outputs, targets))\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets.data).cpu().sum().float()\n",
    "\n",
    "#             progress_bar(batch_idx, len(loader),\n",
    "#                          'Loss: %.3f | Acc: %.3f%% (%d/%d) '\n",
    "#                          % (val_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    acc = 100.*correct/total\n",
    "    logger = logging.getLogger('val')\n",
    "    logger.info('[Epoch {}] [Loss {:.3f}] [Acc {:.3f}]'.format(\n",
    "        epoch,\n",
    "        val_loss/(batch_idx+1),\n",
    "        acc))\n",
    "    print('[Epoch {}] [Loss {:.3f}] [Acc {:.3f}]'.format(\n",
    "        epoch,\n",
    "        val_loss/(batch_idx+1),\n",
    "        acc))\n",
    "\n",
    "    if acc > best_val:\n",
    "        best_val = acc\n",
    "        #checkpoint(acc, epoch)\n",
    "\n",
    "    return (val_loss/(batch_idx+1), acc)\n",
    "\n",
    "\n",
    "def checkpoint(acc, epoch):\n",
    "    # Save checkpoint.\n",
    "    print('Saving..')\n",
    "    state = {\n",
    "        'net': net.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'acc': acc,\n",
    "        'epoch': epoch,\n",
    "        'rng_state': torch.get_rng_state()\n",
    "    }\n",
    "    torch.save(state, os.path.join(logdir, 'ckpt.t7'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"decrease the learning rate at 100 and 150 epoch\"\"\"\n",
    "    lr = args.lr\n",
    "    if epoch >= 0.5 * args.epoch:\n",
    "        lr /= 10\n",
    "    if epoch >= 0.75 * args.epoch:\n",
    "        lr /= 10\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] [Loss 3.948] [cls 0.331] [Acc 9.898]\n",
      "[Epoch 0] [Loss 3.525] [Acc 16.760]\n",
      "[Epoch 1] [Loss 3.275] [cls 0.566] [Acc 21.952]\n",
      "[Epoch 1] [Loss 2.888] [Acc 29.000]\n",
      "[Epoch 2] [Loss 2.702] [cls 0.687] [Acc 33.230]\n",
      "[Epoch 2] [Loss 2.433] [Acc 38.380]\n",
      "[Epoch 3] [Loss 2.296] [cls 0.741] [Acc 42.158]\n",
      "[Epoch 3] [Loss 2.206] [Acc 43.210]\n",
      "[Epoch 4] [Loss 2.006] [cls 0.745] [Acc 49.010]\n",
      "[Epoch 4] [Loss 1.985] [Acc 48.030]\n",
      "[Epoch 5] [Loss 1.795] [cls 0.752] [Acc 53.884]\n",
      "[Epoch 5] [Loss 1.734] [Acc 55.180]\n",
      "[Epoch 6] [Loss 1.633] [cls 0.738] [Acc 57.600]\n",
      "[Epoch 6] [Loss 1.721] [Acc 55.180]\n",
      "[Epoch 7] [Loss 1.493] [cls 0.725] [Acc 61.256]\n",
      "[Epoch 7] [Loss 1.615] [Acc 57.590]\n",
      "[Epoch 8] [Loss 1.389] [cls 0.725] [Acc 64.036]\n",
      "[Epoch 8] [Loss 1.546] [Acc 58.980]\n",
      "[Epoch 9] [Loss 1.290] [cls 0.702] [Acc 66.608]\n",
      "[Epoch 9] [Loss 1.534] [Acc 59.660]\n",
      "[Epoch 10] [Loss 1.218] [cls 0.692] [Acc 67.966]\n",
      "[Epoch 10] [Loss 1.445] [Acc 62.160]\n",
      "[Epoch 11] [Loss 1.147] [cls 0.694] [Acc 70.040]\n",
      "[Epoch 11] [Loss 1.397] [Acc 62.520]\n",
      "[Epoch 12] [Loss 1.099] [cls 0.687] [Acc 71.136]\n",
      "[Epoch 12] [Loss 1.451] [Acc 62.700]\n",
      "[Epoch 13] [Loss 1.035] [cls 0.678] [Acc 72.960]\n",
      "[Epoch 13] [Loss 1.331] [Acc 64.480]\n",
      "[Epoch 14] [Loss 0.985] [cls 0.674] [Acc 74.190]\n",
      "[Epoch 14] [Loss 1.323] [Acc 64.490]\n",
      "[Epoch 15] [Loss 0.938] [cls 0.658] [Acc 75.334]\n",
      "[Epoch 15] [Loss 1.327] [Acc 65.070]\n",
      "[Epoch 16] [Loss 0.896] [cls 0.655] [Acc 76.520]\n",
      "[Epoch 16] [Loss 1.325] [Acc 64.510]\n",
      "[Epoch 17] [Loss 0.862] [cls 0.648] [Acc 77.360]\n",
      "[Epoch 17] [Loss 1.283] [Acc 65.960]\n",
      "[Epoch 18] [Loss 0.830] [cls 0.637] [Acc 78.460]\n",
      "[Epoch 18] [Loss 1.293] [Acc 65.520]\n",
      "[Epoch 19] [Loss 0.791] [cls 0.640] [Acc 79.440]\n",
      "[Epoch 19] [Loss 1.308] [Acc 65.940]\n",
      "[Epoch 20] [Loss 0.767] [cls 0.641] [Acc 80.118]\n",
      "[Epoch 20] [Loss 1.345] [Acc 64.860]\n",
      "[Epoch 21] [Loss 0.742] [cls 0.643] [Acc 80.698]\n",
      "[Epoch 21] [Loss 1.377] [Acc 64.290]\n",
      "[Epoch 22] [Loss 0.711] [cls 0.634] [Acc 81.620]\n",
      "[Epoch 22] [Loss 1.292] [Acc 66.850]\n",
      "[Epoch 23] [Loss 0.686] [cls 0.625] [Acc 82.184]\n",
      "[Epoch 23] [Loss 1.303] [Acc 65.800]\n",
      "[Epoch 24] [Loss 0.662] [cls 0.613] [Acc 83.022]\n",
      "[Epoch 24] [Loss 1.356] [Acc 66.310]\n",
      "[Epoch 25] [Loss 0.640] [cls 0.619] [Acc 83.562]\n",
      "[Epoch 25] [Loss 1.267] [Acc 67.080]\n",
      "[Epoch 26] [Loss 0.621] [cls 0.628] [Acc 83.966]\n",
      "[Epoch 26] [Loss 1.268] [Acc 66.920]\n",
      "[Epoch 27] [Loss 0.601] [cls 0.603] [Acc 84.694]\n",
      "[Epoch 27] [Loss 1.292] [Acc 67.340]\n",
      "[Epoch 28] [Loss 0.577] [cls 0.603] [Acc 85.326]\n",
      "[Epoch 28] [Loss 1.273] [Acc 66.980]\n",
      "[Epoch 29] [Loss 0.565] [cls 0.599] [Acc 85.526]\n",
      "[Epoch 29] [Loss 1.227] [Acc 67.690]\n",
      "[Epoch 30] [Loss 0.555] [cls 0.591] [Acc 85.734]\n",
      "[Epoch 30] [Loss 1.240] [Acc 67.130]\n",
      "[Epoch 31] [Loss 0.525] [cls 0.576] [Acc 86.656]\n",
      "[Epoch 31] [Loss 1.265] [Acc 67.800]\n",
      "[Epoch 32] [Loss 0.516] [cls 0.586] [Acc 87.020]\n",
      "[Epoch 32] [Loss 1.214] [Acc 68.000]\n",
      "[Epoch 33] [Loss 0.517] [cls 0.592] [Acc 86.758]\n",
      "[Epoch 33] [Loss 1.233] [Acc 68.100]\n",
      "[Epoch 34] [Loss 0.503] [cls 0.582] [Acc 87.462]\n",
      "[Epoch 34] [Loss 1.216] [Acc 68.480]\n",
      "[Epoch 35] [Loss 0.485] [cls 0.576] [Acc 87.964]\n",
      "[Epoch 35] [Loss 1.234] [Acc 67.970]\n",
      "[Epoch 36] [Loss 0.475] [cls 0.585] [Acc 88.120]\n",
      "[Epoch 36] [Loss 1.234] [Acc 68.120]\n",
      "[Epoch 37] [Loss 0.466] [cls 0.580] [Acc 88.394]\n",
      "[Epoch 37] [Loss 1.302] [Acc 67.060]\n",
      "[Epoch 38] [Loss 0.462] [cls 0.581] [Acc 88.422]\n",
      "[Epoch 38] [Loss 1.203] [Acc 69.170]\n",
      "[Epoch 39] [Loss 0.438] [cls 0.557] [Acc 89.158]\n",
      "[Epoch 39] [Loss 1.317] [Acc 67.220]\n",
      "[Epoch 40] [Loss 0.436] [cls 0.558] [Acc 89.200]\n",
      "[Epoch 40] [Loss 1.243] [Acc 68.910]\n",
      "[Epoch 41] [Loss 0.435] [cls 0.573] [Acc 89.200]\n",
      "[Epoch 41] [Loss 1.207] [Acc 68.920]\n",
      "[Epoch 42] [Loss 0.432] [cls 0.563] [Acc 89.094]\n",
      "[Epoch 42] [Loss 1.313] [Acc 67.070]\n",
      "[Epoch 43] [Loss 0.422] [cls 0.572] [Acc 89.644]\n",
      "[Epoch 43] [Loss 1.333] [Acc 66.930]\n",
      "[Epoch 44] [Loss 0.406] [cls 0.555] [Acc 90.026]\n",
      "[Epoch 44] [Loss 1.250] [Acc 68.260]\n",
      "[Epoch 45] [Loss 0.422] [cls 0.576] [Acc 89.416]\n",
      "[Epoch 45] [Loss 1.223] [Acc 68.930]\n",
      "[Epoch 46] [Loss 0.394] [cls 0.557] [Acc 90.340]\n",
      "[Epoch 46] [Loss 1.249] [Acc 68.360]\n",
      "[Epoch 47] [Loss 0.400] [cls 0.552] [Acc 90.222]\n",
      "[Epoch 47] [Loss 1.213] [Acc 69.350]\n",
      "[Epoch 48] [Loss 0.391] [cls 0.551] [Acc 90.376]\n",
      "[Epoch 48] [Loss 1.305] [Acc 67.450]\n",
      "[Epoch 49] [Loss 0.384] [cls 0.544] [Acc 90.642]\n",
      "[Epoch 49] [Loss 1.231] [Acc 68.880]\n",
      "[Epoch 50] [Loss 0.367] [cls 0.550] [Acc 90.966]\n",
      "[Epoch 50] [Loss 1.271] [Acc 67.720]\n",
      "[Epoch 51] [Loss 0.368] [cls 0.551] [Acc 90.994]\n",
      "[Epoch 51] [Loss 1.290] [Acc 67.400]\n",
      "[Epoch 52] [Loss 0.368] [cls 0.545] [Acc 91.046]\n",
      "[Epoch 52] [Loss 1.304] [Acc 67.480]\n",
      "[Epoch 53] [Loss 0.359] [cls 0.543] [Acc 91.270]\n",
      "[Epoch 53] [Loss 1.211] [Acc 69.240]\n",
      "[Epoch 54] [Loss 0.341] [cls 0.528] [Acc 91.768]\n",
      "[Epoch 54] [Loss 1.218] [Acc 69.520]\n",
      "[Epoch 55] [Loss 0.368] [cls 0.553] [Acc 91.102]\n",
      "[Epoch 55] [Loss 1.418] [Acc 64.730]\n",
      "[Epoch 56] [Loss 0.394] [cls 0.565] [Acc 90.264]\n",
      "[Epoch 56] [Loss 1.277] [Acc 67.700]\n",
      "[Epoch 57] [Loss 0.351] [cls 0.542] [Acc 91.504]\n",
      "[Epoch 57] [Loss 1.312] [Acc 67.500]\n",
      "[Epoch 58] [Loss 0.354] [cls 0.523] [Acc 91.588]\n",
      "[Epoch 58] [Loss 1.247] [Acc 68.740]\n",
      "[Epoch 59] [Loss 0.340] [cls 0.529] [Acc 91.716]\n",
      "[Epoch 59] [Loss 1.218] [Acc 69.740]\n",
      "[Epoch 60] [Loss 0.326] [cls 0.518] [Acc 92.300]\n",
      "[Epoch 60] [Loss 1.240] [Acc 68.770]\n",
      "[Epoch 61] [Loss 0.344] [cls 0.528] [Acc 91.710]\n",
      "[Epoch 61] [Loss 1.303] [Acc 68.050]\n",
      "[Epoch 62] [Loss 0.345] [cls 0.536] [Acc 91.644]\n",
      "[Epoch 62] [Loss 1.333] [Acc 66.940]\n",
      "[Epoch 63] [Loss 0.332] [cls 0.526] [Acc 92.064]\n",
      "[Epoch 63] [Loss 1.382] [Acc 65.720]\n",
      "[Epoch 64] [Loss 0.344] [cls 0.540] [Acc 91.754]\n",
      "[Epoch 64] [Loss 1.323] [Acc 67.550]\n",
      "[Epoch 65] [Loss 0.325] [cls 0.520] [Acc 92.216]\n",
      "[Epoch 65] [Loss 1.253] [Acc 68.880]\n",
      "[Epoch 66] [Loss 0.344] [cls 0.537] [Acc 91.602]\n",
      "[Epoch 66] [Loss 1.186] [Acc 70.300]\n",
      "[Epoch 67] [Loss 0.335] [cls 0.545] [Acc 91.918]\n",
      "[Epoch 67] [Loss 1.205] [Acc 69.490]\n",
      "[Epoch 68] [Loss 0.319] [cls 0.516] [Acc 92.464]\n",
      "[Epoch 68] [Loss 1.287] [Acc 68.170]\n",
      "[Epoch 69] [Loss 0.320] [cls 0.517] [Acc 92.326]\n",
      "[Epoch 69] [Loss 1.296] [Acc 67.850]\n",
      "[Epoch 70] [Loss 0.301] [cls 0.487] [Acc 93.116]\n",
      "[Epoch 70] [Loss 1.232] [Acc 69.570]\n",
      "[Epoch 71] [Loss 0.317] [cls 0.522] [Acc 92.378]\n",
      "[Epoch 71] [Loss 1.226] [Acc 69.200]\n",
      "[Epoch 72] [Loss 0.322] [cls 0.503] [Acc 92.392]\n",
      "[Epoch 72] [Loss 1.260] [Acc 68.660]\n",
      "[Epoch 73] [Loss 0.316] [cls 0.514] [Acc 92.466]\n",
      "[Epoch 73] [Loss 1.274] [Acc 68.750]\n",
      "[Epoch 74] [Loss 0.305] [cls 0.506] [Acc 92.812]\n",
      "[Epoch 74] [Loss 1.308] [Acc 66.990]\n",
      "[Epoch 75] [Loss 0.301] [cls 0.508] [Acc 92.804]\n",
      "[Epoch 75] [Loss 1.308] [Acc 68.030]\n",
      "[Epoch 76] [Loss 0.308] [cls 0.511] [Acc 92.764]\n",
      "[Epoch 76] [Loss 1.274] [Acc 68.380]\n",
      "[Epoch 77] [Loss 0.308] [cls 0.510] [Acc 92.712]\n",
      "[Epoch 77] [Loss 1.263] [Acc 69.060]\n",
      "[Epoch 78] [Loss 0.297] [cls 0.499] [Acc 93.028]\n",
      "[Epoch 78] [Loss 1.352] [Acc 66.540]\n",
      "[Epoch 79] [Loss 0.301] [cls 0.499] [Acc 92.888]\n",
      "[Epoch 79] [Loss 1.262] [Acc 68.660]\n",
      "[Epoch 80] [Loss 0.291] [cls 0.494] [Acc 93.164]\n",
      "[Epoch 80] [Loss 1.293] [Acc 68.210]\n",
      "[Epoch 81] [Loss 0.310] [cls 0.523] [Acc 92.540]\n",
      "[Epoch 81] [Loss 1.264] [Acc 68.360]\n",
      "[Epoch 82] [Loss 0.304] [cls 0.519] [Acc 92.864]\n",
      "[Epoch 82] [Loss 1.374] [Acc 67.000]\n",
      "[Epoch 83] [Loss 0.297] [cls 0.499] [Acc 93.086]\n",
      "[Epoch 83] [Loss 1.257] [Acc 69.030]\n",
      "[Epoch 84] [Loss 0.299] [cls 0.505] [Acc 92.998]\n",
      "[Epoch 84] [Loss 1.247] [Acc 69.110]\n",
      "[Epoch 85] [Loss 0.280] [cls 0.481] [Acc 93.594]\n",
      "[Epoch 85] [Loss 1.219] [Acc 69.770]\n",
      "[Epoch 86] [Loss 0.275] [cls 0.480] [Acc 93.670]\n",
      "[Epoch 86] [Loss 1.231] [Acc 69.840]\n",
      "[Epoch 87] [Loss 0.299] [cls 0.486] [Acc 93.054]\n",
      "[Epoch 87] [Loss 1.246] [Acc 68.470]\n",
      "[Epoch 88] [Loss 0.286] [cls 0.501] [Acc 93.298]\n",
      "[Epoch 88] [Loss 1.352] [Acc 66.850]\n",
      "[Epoch 89] [Loss 0.303] [cls 0.517] [Acc 92.902]\n",
      "[Epoch 89] [Loss 1.293] [Acc 67.940]\n",
      "[Epoch 90] [Loss 0.328] [cls 0.528] [Acc 92.084]\n",
      "[Epoch 90] [Loss 1.244] [Acc 69.080]\n",
      "[Epoch 91] [Loss 0.302] [cls 0.518] [Acc 92.850]\n",
      "[Epoch 91] [Loss 1.249] [Acc 68.990]\n",
      "[Epoch 92] [Loss 0.300] [cls 0.512] [Acc 92.866]\n",
      "[Epoch 92] [Loss 1.354] [Acc 67.320]\n",
      "[Epoch 93] [Loss 0.286] [cls 0.493] [Acc 93.330]\n",
      "[Epoch 93] [Loss 1.326] [Acc 68.150]\n",
      "[Epoch 94] [Loss 0.292] [cls 0.515] [Acc 93.176]\n",
      "[Epoch 94] [Loss 1.232] [Acc 69.500]\n",
      "[Epoch 95] [Loss 0.283] [cls 0.501] [Acc 93.286]\n",
      "[Epoch 95] [Loss 1.239] [Acc 68.470]\n",
      "[Epoch 96] [Loss 0.289] [cls 0.508] [Acc 93.172]\n",
      "[Epoch 96] [Loss 1.272] [Acc 69.040]\n",
      "[Epoch 97] [Loss 0.276] [cls 0.479] [Acc 93.588]\n",
      "[Epoch 97] [Loss 1.251] [Acc 68.860]\n",
      "[Epoch 98] [Loss 0.288] [cls 0.495] [Acc 93.220]\n",
      "[Epoch 98] [Loss 1.247] [Acc 69.860]\n",
      "[Epoch 99] [Loss 0.290] [cls 0.499] [Acc 93.116]\n",
      "[Epoch 99] [Loss 1.334] [Acc 67.780]\n",
      "[Epoch 100] [Loss 0.272] [cls 0.477] [Acc 93.850]\n",
      "[Epoch 100] [Loss 1.230] [Acc 69.150]\n",
      "[Epoch 101] [Loss 0.115] [cls 0.328] [Acc 98.174]\n",
      "[Epoch 101] [Loss 0.938] [Acc 75.850]\n",
      "[Epoch 102] [Loss 0.075] [cls 0.248] [Acc 99.256]\n",
      "[Epoch 102] [Loss 0.929] [Acc 75.990]\n",
      "[Epoch 103] [Loss 0.063] [cls 0.221] [Acc 99.462]\n",
      "[Epoch 103] [Loss 0.915] [Acc 76.570]\n",
      "[Epoch 104] [Loss 0.056] [cls 0.210] [Acc 99.566]\n",
      "[Epoch 104] [Loss 0.916] [Acc 76.970]\n",
      "[Epoch 105] [Loss 0.050] [cls 0.204] [Acc 99.620]\n",
      "[Epoch 105] [Loss 0.920] [Acc 76.690]\n",
      "[Epoch 106] [Loss 0.048] [cls 0.189] [Acc 99.686]\n",
      "[Epoch 106] [Loss 0.915] [Acc 76.870]\n",
      "[Epoch 107] [Loss 0.043] [cls 0.192] [Acc 99.750]\n",
      "[Epoch 107] [Loss 0.915] [Acc 77.050]\n",
      "[Epoch 108] [Loss 0.041] [cls 0.182] [Acc 99.768]\n",
      "[Epoch 108] [Loss 0.907] [Acc 76.960]\n",
      "[Epoch 109] [Loss 0.040] [cls 0.176] [Acc 99.774]\n",
      "[Epoch 109] [Loss 0.907] [Acc 77.210]\n",
      "[Epoch 110] [Loss 0.038] [cls 0.168] [Acc 99.802]\n",
      "[Epoch 110] [Loss 0.909] [Acc 77.260]\n",
      "[Epoch 111] [Loss 0.036] [cls 0.167] [Acc 99.800]\n",
      "[Epoch 111] [Loss 0.906] [Acc 77.270]\n",
      "[Epoch 112] [Loss 0.035] [cls 0.163] [Acc 99.826]\n",
      "[Epoch 112] [Loss 0.910] [Acc 77.410]\n",
      "[Epoch 113] [Loss 0.034] [cls 0.156] [Acc 99.824]\n",
      "[Epoch 113] [Loss 0.918] [Acc 77.090]\n",
      "[Epoch 114] [Loss 0.032] [cls 0.160] [Acc 99.840]\n",
      "[Epoch 114] [Loss 0.915] [Acc 77.180]\n",
      "[Epoch 115] [Loss 0.031] [cls 0.155] [Acc 99.840]\n",
      "[Epoch 115] [Loss 0.914] [Acc 77.360]\n",
      "[Epoch 116] [Loss 0.030] [cls 0.149] [Acc 99.884]\n",
      "[Epoch 116] [Loss 0.919] [Acc 77.230]\n",
      "[Epoch 117] [Loss 0.029] [cls 0.151] [Acc 99.860]\n",
      "[Epoch 117] [Loss 0.915] [Acc 77.280]\n",
      "[Epoch 118] [Loss 0.029] [cls 0.143] [Acc 99.850]\n",
      "[Epoch 118] [Loss 0.907] [Acc 77.500]\n",
      "[Epoch 119] [Loss 0.028] [cls 0.144] [Acc 99.880]\n",
      "[Epoch 119] [Loss 0.914] [Acc 77.160]\n",
      "[Epoch 120] [Loss 0.027] [cls 0.138] [Acc 99.894]\n",
      "[Epoch 120] [Loss 0.917] [Acc 77.440]\n",
      "[Epoch 121] [Loss 0.026] [cls 0.137] [Acc 99.908]\n",
      "[Epoch 121] [Loss 0.910] [Acc 77.440]\n",
      "[Epoch 122] [Loss 0.026] [cls 0.135] [Acc 99.918]\n",
      "[Epoch 122] [Loss 0.915] [Acc 77.200]\n",
      "[Epoch 123] [Loss 0.025] [cls 0.135] [Acc 99.906]\n",
      "[Epoch 123] [Loss 0.913] [Acc 77.170]\n",
      "[Epoch 124] [Loss 0.023] [cls 0.136] [Acc 99.912]\n",
      "[Epoch 124] [Loss 0.914] [Acc 77.200]\n",
      "[Epoch 125] [Loss 0.025] [cls 0.125] [Acc 99.904]\n",
      "[Epoch 125] [Loss 0.916] [Acc 77.240]\n",
      "[Epoch 126] [Loss 0.022] [cls 0.133] [Acc 99.910]\n",
      "[Epoch 126] [Loss 0.924] [Acc 77.340]\n",
      "[Epoch 127] [Loss 0.024] [cls 0.124] [Acc 99.912]\n",
      "[Epoch 127] [Loss 0.914] [Acc 77.450]\n",
      "[Epoch 128] [Loss 0.022] [cls 0.127] [Acc 99.914]\n",
      "[Epoch 128] [Loss 0.912] [Acc 77.620]\n",
      "[Epoch 129] [Loss 0.022] [cls 0.127] [Acc 99.936]\n",
      "[Epoch 129] [Loss 0.917] [Acc 77.390]\n",
      "[Epoch 130] [Loss 0.023] [cls 0.120] [Acc 99.922]\n",
      "[Epoch 130] [Loss 0.920] [Acc 77.450]\n",
      "[Epoch 131] [Loss 0.022] [cls 0.118] [Acc 99.916]\n",
      "[Epoch 131] [Loss 0.924] [Acc 77.640]\n",
      "[Epoch 132] [Loss 0.023] [cls 0.115] [Acc 99.918]\n",
      "[Epoch 132] [Loss 0.918] [Acc 77.560]\n",
      "[Epoch 133] [Loss 0.020] [cls 0.121] [Acc 99.942]\n",
      "[Epoch 133] [Loss 0.926] [Acc 77.200]\n",
      "[Epoch 134] [Loss 0.020] [cls 0.119] [Acc 99.936]\n",
      "[Epoch 134] [Loss 0.917] [Acc 77.380]\n",
      "[Epoch 135] [Loss 0.021] [cls 0.112] [Acc 99.944]\n",
      "[Epoch 135] [Loss 0.917] [Acc 77.460]\n",
      "[Epoch 136] [Loss 0.020] [cls 0.115] [Acc 99.940]\n",
      "[Epoch 136] [Loss 0.921] [Acc 77.440]\n",
      "[Epoch 137] [Loss 0.018] [cls 0.119] [Acc 99.950]\n",
      "[Epoch 137] [Loss 0.922] [Acc 77.380]\n",
      "[Epoch 138] [Loss 0.021] [cls 0.107] [Acc 99.934]\n",
      "[Epoch 138] [Loss 0.925] [Acc 77.250]\n",
      "[Epoch 139] [Loss 0.019] [cls 0.110] [Acc 99.944]\n",
      "[Epoch 139] [Loss 0.916] [Acc 77.570]\n",
      "[Epoch 140] [Loss 0.018] [cls 0.111] [Acc 99.932]\n",
      "[Epoch 140] [Loss 0.923] [Acc 77.350]\n",
      "[Epoch 141] [Loss 0.018] [cls 0.111] [Acc 99.962]\n",
      "[Epoch 141] [Loss 0.920] [Acc 77.490]\n",
      "[Epoch 142] [Loss 0.019] [cls 0.107] [Acc 99.940]\n",
      "[Epoch 142] [Loss 0.927] [Acc 77.380]\n",
      "[Epoch 143] [Loss 0.019] [cls 0.105] [Acc 99.942]\n",
      "[Epoch 143] [Loss 0.927] [Acc 77.490]\n",
      "[Epoch 144] [Loss 0.019] [cls 0.103] [Acc 99.944]\n",
      "[Epoch 144] [Loss 0.927] [Acc 77.330]\n",
      "[Epoch 145] [Loss 0.018] [cls 0.102] [Acc 99.946]\n",
      "[Epoch 145] [Loss 0.924] [Acc 77.560]\n",
      "[Epoch 146] [Loss 0.018] [cls 0.102] [Acc 99.950]\n",
      "[Epoch 146] [Loss 0.930] [Acc 77.490]\n",
      "[Epoch 147] [Loss 0.017] [cls 0.103] [Acc 99.956]\n",
      "[Epoch 147] [Loss 0.934] [Acc 77.350]\n",
      "[Epoch 148] [Loss 0.016] [cls 0.105] [Acc 99.940]\n",
      "[Epoch 148] [Loss 0.928] [Acc 77.330]\n",
      "[Epoch 149] [Loss 0.018] [cls 0.099] [Acc 99.950]\n",
      "[Epoch 149] [Loss 0.926] [Acc 77.550]\n",
      "[Epoch 150] [Loss 0.018] [cls 0.097] [Acc 99.952]\n",
      "[Epoch 150] [Loss 0.927] [Acc 77.430]\n",
      "[Epoch 151] [Loss 0.015] [cls 0.102] [Acc 99.964]\n",
      "[Epoch 151] [Loss 0.926] [Acc 77.640]\n",
      "[Epoch 152] [Loss 0.015] [cls 0.096] [Acc 99.960]\n",
      "[Epoch 152] [Loss 0.926] [Acc 77.600]\n",
      "[Epoch 153] [Loss 0.017] [cls 0.092] [Acc 99.964]\n",
      "[Epoch 153] [Loss 0.922] [Acc 77.620]\n",
      "[Epoch 154] [Loss 0.016] [cls 0.093] [Acc 99.966]\n",
      "[Epoch 154] [Loss 0.924] [Acc 77.640]\n",
      "[Epoch 155] [Loss 0.016] [cls 0.092] [Acc 99.962]\n",
      "[Epoch 155] [Loss 0.923] [Acc 77.570]\n",
      "[Epoch 156] [Loss 0.017] [cls 0.092] [Acc 99.958]\n",
      "[Epoch 156] [Loss 0.924] [Acc 77.580]\n",
      "[Epoch 157] [Loss 0.017] [cls 0.092] [Acc 99.942]\n",
      "[Epoch 157] [Loss 0.922] [Acc 77.650]\n",
      "[Epoch 158] [Loss 0.016] [cls 0.092] [Acc 99.954]\n",
      "[Epoch 158] [Loss 0.924] [Acc 77.540]\n",
      "[Epoch 159] [Loss 0.016] [cls 0.090] [Acc 99.968]\n",
      "[Epoch 159] [Loss 0.926] [Acc 77.640]\n",
      "[Epoch 160] [Loss 0.016] [cls 0.090] [Acc 99.966]\n",
      "[Epoch 160] [Loss 0.922] [Acc 77.710]\n",
      "[Epoch 161] [Loss 0.016] [cls 0.090] [Acc 99.964]\n",
      "[Epoch 161] [Loss 0.923] [Acc 77.770]\n",
      "[Epoch 162] [Loss 0.015] [cls 0.093] [Acc 99.974]\n",
      "[Epoch 162] [Loss 0.921] [Acc 77.650]\n",
      "[Epoch 163] [Loss 0.016] [cls 0.091] [Acc 99.978]\n",
      "[Epoch 163] [Loss 0.924] [Acc 77.660]\n",
      "[Epoch 164] [Loss 0.016] [cls 0.091] [Acc 99.950]\n",
      "[Epoch 164] [Loss 0.923] [Acc 77.740]\n",
      "[Epoch 165] [Loss 0.016] [cls 0.090] [Acc 99.966]\n",
      "[Epoch 165] [Loss 0.921] [Acc 77.550]\n",
      "[Epoch 166] [Loss 0.016] [cls 0.090] [Acc 99.956]\n",
      "[Epoch 166] [Loss 0.923] [Acc 77.760]\n",
      "[Epoch 167] [Loss 0.016] [cls 0.090] [Acc 99.968]\n",
      "[Epoch 167] [Loss 0.921] [Acc 77.820]\n",
      "[Epoch 168] [Loss 0.016] [cls 0.089] [Acc 99.962]\n",
      "[Epoch 168] [Loss 0.925] [Acc 77.690]\n",
      "[Epoch 169] [Loss 0.015] [cls 0.090] [Acc 99.970]\n",
      "[Epoch 169] [Loss 0.922] [Acc 77.750]\n",
      "[Epoch 170] [Loss 0.016] [cls 0.090] [Acc 99.970]\n",
      "[Epoch 170] [Loss 0.923] [Acc 77.760]\n",
      "[Epoch 171] [Loss 0.015] [cls 0.091] [Acc 99.962]\n",
      "[Epoch 171] [Loss 0.925] [Acc 77.770]\n",
      "[Epoch 172] [Loss 0.016] [cls 0.089] [Acc 99.962]\n",
      "[Epoch 172] [Loss 0.926] [Acc 77.660]\n",
      "[Epoch 173] [Loss 0.016] [cls 0.087] [Acc 99.964]\n",
      "[Epoch 173] [Loss 0.924] [Acc 77.650]\n",
      "[Epoch 174] [Loss 0.015] [cls 0.091] [Acc 99.964]\n",
      "[Epoch 174] [Loss 0.921] [Acc 77.620]\n",
      "[Epoch 175] [Loss 0.015] [cls 0.089] [Acc 99.966]\n",
      "[Epoch 175] [Loss 0.922] [Acc 77.750]\n",
      "[Epoch 176] [Loss 0.016] [cls 0.088] [Acc 99.954]\n",
      "[Epoch 176] [Loss 0.924] [Acc 77.640]\n",
      "[Epoch 177] [Loss 0.016] [cls 0.087] [Acc 99.966]\n",
      "[Epoch 177] [Loss 0.925] [Acc 77.640]\n",
      "[Epoch 178] [Loss 0.015] [cls 0.089] [Acc 99.972]\n",
      "[Epoch 178] [Loss 0.921] [Acc 77.610]\n",
      "[Epoch 179] [Loss 0.015] [cls 0.091] [Acc 99.960]\n",
      "[Epoch 179] [Loss 0.919] [Acc 77.650]\n",
      "[Epoch 180] [Loss 0.015] [cls 0.092] [Acc 99.950]\n",
      "[Epoch 180] [Loss 0.922] [Acc 77.670]\n",
      "[Epoch 181] [Loss 0.014] [cls 0.090] [Acc 99.972]\n",
      "[Epoch 181] [Loss 0.921] [Acc 77.720]\n",
      "[Epoch 182] [Loss 0.014] [cls 0.092] [Acc 99.962]\n",
      "[Epoch 182] [Loss 0.922] [Acc 77.750]\n",
      "[Epoch 183] [Loss 0.014] [cls 0.090] [Acc 99.970]\n",
      "[Epoch 183] [Loss 0.923] [Acc 77.470]\n",
      "[Epoch 184] [Loss 0.015] [cls 0.090] [Acc 99.970]\n",
      "[Epoch 184] [Loss 0.923] [Acc 77.800]\n",
      "[Epoch 185] [Loss 0.015] [cls 0.089] [Acc 99.966]\n",
      "[Epoch 185] [Loss 0.924] [Acc 77.650]\n",
      "[Epoch 186] [Loss 0.015] [cls 0.089] [Acc 99.972]\n",
      "[Epoch 186] [Loss 0.925] [Acc 77.650]\n",
      "[Epoch 187] [Loss 0.015] [cls 0.088] [Acc 99.966]\n",
      "[Epoch 187] [Loss 0.920] [Acc 77.690]\n",
      "[Epoch 188] [Loss 0.015] [cls 0.088] [Acc 99.968]\n",
      "[Epoch 188] [Loss 0.924] [Acc 77.820]\n",
      "[Epoch 189] [Loss 0.016] [cls 0.087] [Acc 99.966]\n",
      "[Epoch 189] [Loss 0.924] [Acc 77.650]\n",
      "[Epoch 190] [Loss 0.015] [cls 0.086] [Acc 99.966]\n",
      "[Epoch 190] [Loss 0.925] [Acc 77.650]\n",
      "[Epoch 191] [Loss 0.015] [cls 0.088] [Acc 99.972]\n",
      "[Epoch 191] [Loss 0.922] [Acc 77.570]\n",
      "[Epoch 192] [Loss 0.015] [cls 0.089] [Acc 99.956]\n",
      "[Epoch 192] [Loss 0.925] [Acc 77.430]\n",
      "[Epoch 193] [Loss 0.015] [cls 0.088] [Acc 99.966]\n",
      "[Epoch 193] [Loss 0.922] [Acc 77.700]\n",
      "[Epoch 194] [Loss 0.015] [cls 0.088] [Acc 99.958]\n",
      "[Epoch 194] [Loss 0.923] [Acc 77.700]\n",
      "[Epoch 195] [Loss 0.015] [cls 0.088] [Acc 99.970]\n",
      "[Epoch 195] [Loss 0.926] [Acc 77.660]\n",
      "[Epoch 196] [Loss 0.015] [cls 0.087] [Acc 99.974]\n",
      "[Epoch 196] [Loss 0.924] [Acc 77.550]\n",
      "[Epoch 197] [Loss 0.015] [cls 0.087] [Acc 99.962]\n",
      "[Epoch 197] [Loss 0.923] [Acc 77.590]\n",
      "[Epoch 198] [Loss 0.015] [cls 0.086] [Acc 99.964]\n",
      "[Epoch 198] [Loss 0.926] [Acc 77.480]\n",
      "[Epoch 199] [Loss 0.015] [cls 0.086] [Acc 99.960]\n",
      "[Epoch 199] [Loss 0.922] [Acc 77.680]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, args.epoch):\n",
    "    #print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    train_cls_loss = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "        batch_size = inputs.size(0)\n",
    "        \n",
    "        # 앞의 batch_size 개수만큼 인풋으로 들어감. -> training에 쓰이는 인풋\n",
    "        targets_ = targets[:batch_size//2]\n",
    "        outputs = net(inputs[:batch_size//2])\n",
    "        \n",
    "        # CE loss -> do we need this?\n",
    "        loss = torch.mean(criterion(outputs, targets_))\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # 뒤의 batch size 개수도 인풋으로 들어가지만, target probability 를 뽑는 용도로 학습은 X\n",
    "        with torch.no_grad():\n",
    "            outputs_cls = net(inputs[batch_size//2:])\n",
    "        \n",
    "        # KD loss\n",
    "        cls_loss = kdloss(outputs, outputs_cls.detach())\n",
    "        loss += args.lamda * cls_loss\n",
    "        train_cls_loss += cls_loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += targets_.size(0)\n",
    "        correct += predicted.eq(targets_.data).sum().float().cpu()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         progress_bar(batch_idx, len(trainloader),\n",
    "#                      'Loss: %.3f | Acc: %.3f%% (%d/%d) | Cls: %.3f '\n",
    "#                      % (train_loss/(batch_idx+1), 100.*correct/total, correct, total, train_cls_loss/(batch_idx+1)))\n",
    "\n",
    "    logger = logging.getLogger('train')\n",
    "    logger.info('[Epoch {}] [Loss {:.3f}] [cls {:.3f}] [Acc {:.3f}]'.format(\n",
    "        epoch,\n",
    "        train_loss/(batch_idx+1),\n",
    "        train_cls_loss/(batch_idx+1),\n",
    "        100.*correct/total))\n",
    "    print('[Epoch {}] [Loss {:.3f}] [cls {:.3f}] [Acc {:.3f}]'.format(\n",
    "        epoch,\n",
    "        train_loss/(batch_idx+1),\n",
    "        train_cls_loss/(batch_idx+1),\n",
    "        100.*correct/total))\n",
    "\n",
    "    val_loss, val_acc = val(epoch)\n",
    "    adjust_learning_rate(optimizer, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습된 네트워크로 self-distillation target 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 32, 32]) torch.Size([256])\n",
      "tensor(15, device='cuda:0')\n",
      "tensor([0.0074, 0.0084, 0.0095, 0.0129, 0.0109, 0.0074, 0.0089, 0.0077, 0.0081,\n",
      "        0.0079, 0.0087, 0.0088, 0.0082, 0.0081, 0.0090, 0.1097, 0.0082, 0.0080,\n",
      "        0.0086, 0.0147, 0.0071, 0.0117, 0.0084, 0.0089, 0.0073, 0.0078, 0.0086,\n",
      "        0.0086, 0.0078, 0.0118, 0.0085, 0.0139, 0.0103, 0.0092, 0.0101, 0.0102,\n",
      "        0.0102, 0.0082, 0.0133, 0.0078, 0.0090, 0.0077, 0.0100, 0.0099, 0.0103,\n",
      "        0.0086, 0.0096, 0.0077, 0.0075, 0.0085, 0.0108, 0.0092, 0.0077, 0.0080,\n",
      "        0.0077, 0.0123, 0.0075, 0.0081, 0.0078, 0.0082, 0.0076, 0.0072, 0.0084,\n",
      "        0.0104, 0.0108, 0.0110, 0.0087, 0.0101, 0.0075, 0.0078, 0.0079, 0.0084,\n",
      "        0.0117, 0.0089, 0.0108, 0.0091, 0.0072, 0.0092, 0.0087, 0.0088, 0.0108,\n",
      "        0.0072, 0.0081, 0.0075, 0.0084, 0.0078, 0.0083, 0.0091, 0.0094, 0.0083,\n",
      "        0.0074, 0.0079, 0.0078, 0.0098, 0.0087, 0.0090, 0.0078, 0.0115, 0.0093,\n",
      "        0.0086], device='cuda:0') tensor(0.1097, device='cuda:0')\n",
      "tensor([0.0072, 0.0081, 0.0096, 0.0118, 0.0108, 0.0077, 0.0093, 0.0077, 0.0085,\n",
      "        0.0080, 0.0088, 0.0088, 0.0081, 0.0078, 0.0086, 0.1203, 0.0083, 0.0082,\n",
      "        0.0083, 0.0145, 0.0071, 0.0102, 0.0089, 0.0091, 0.0073, 0.0077, 0.0087,\n",
      "        0.0088, 0.0079, 0.0123, 0.0082, 0.0139, 0.0107, 0.0092, 0.0093, 0.0094,\n",
      "        0.0097, 0.0081, 0.0127, 0.0080, 0.0092, 0.0077, 0.0095, 0.0091, 0.0101,\n",
      "        0.0085, 0.0096, 0.0078, 0.0075, 0.0089, 0.0105, 0.0091, 0.0081, 0.0083,\n",
      "        0.0081, 0.0113, 0.0076, 0.0080, 0.0079, 0.0081, 0.0078, 0.0075, 0.0083,\n",
      "        0.0098, 0.0099, 0.0109, 0.0082, 0.0100, 0.0073, 0.0081, 0.0081, 0.0085,\n",
      "        0.0112, 0.0091, 0.0116, 0.0084, 0.0074, 0.0087, 0.0083, 0.0089, 0.0106,\n",
      "        0.0075, 0.0079, 0.0073, 0.0087, 0.0079, 0.0078, 0.0085, 0.0086, 0.0083,\n",
      "        0.0077, 0.0080, 0.0076, 0.0095, 0.0082, 0.0085, 0.0077, 0.0117, 0.0092,\n",
      "        0.0082], device='cuda:0', grad_fn=<SoftmaxBackward>) tensor(0.1203, device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs, targets = next(iter(trainloader))\n",
    "#inputs, targets = inputs.cuda(), targets.cuda()\n",
    "print(inputs.size(), targets.size())\n",
    "\n",
    "split_idx = inputs.size(0) // 2\n",
    "grid = torchvision.utils.make_grid(torch.stack((inputs[0], inputs[split_idx]), 0), normalize=True)\n",
    "plt.imshow(np.transpose(grid.numpy(), (1,2,0)))\n",
    "\n",
    "inputs, targets = inputs.cuda(), targets.cuda()\n",
    "targets_ = targets[0]\n",
    "outputs = net(inputs[:split_idx])\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs_cls = net(inputs[split_idx:])\n",
    "\n",
    "outputs_ = outputs[0]\n",
    "outputs_cls_ = outputs_cls[0]\n",
    "\n",
    "predict_prob = torch.softmax(outputs_cls_/args.temp, 0)\n",
    "target_prob = torch.softmax(outputs_/args.temp, 0)\n",
    "\n",
    "print(targets_)\n",
    "print(predict_prob, predict_prob[targets_])\n",
    "print(target_prob, target_prob[targets_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.1203, 0.0145, 0.0139], device='cuda:0', grad_fn=<TopkBackward>),\n",
       "indices=tensor([15, 19, 31], device='cuda:0'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(target_prob, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'camel'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader.dataset.base_dataset.classes[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
